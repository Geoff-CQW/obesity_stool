
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Data cleaning and explorations &#8212; My Jupyter Book</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint single-page" id="site-navigation">
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/Project.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/Project.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Data cleaning and explorations
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#logistic-regression">
   Logistic regression
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#partial-least-squares-discriminant-analysis">
   Partial least squares discriminant analysis
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-little-experiment">
   <em>
    a little experiment ….
   </em>
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#kernel-svm">
   Kernel SVM
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#random-forest">
   Random Forest
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#adaboost">
   Adaboost
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gradient-boosting">
   Gradient Boosting
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feature-importance">
   feature importance
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#one-last-model">
   <em>
    one last model
   </em>
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Data cleaning and explorations</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Data cleaning and explorations
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#logistic-regression">
   Logistic regression
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#partial-least-squares-discriminant-analysis">
   Partial least squares discriminant analysis
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-little-experiment">
   <em>
    a little experiment ….
   </em>
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#kernel-svm">
   Kernel SVM
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#random-forest">
   Random Forest
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#adaboost">
   Adaboost
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#gradient-boosting">
   Gradient Boosting
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feature-importance">
   feature importance
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#one-last-model">
   <em>
    one last model
   </em>
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <h1> Stool microbiome and obesity </h1>
<p>The microbiome refers to all the microorganisms that live on or within the human body. Microorganisms can be found thriving in many sites of the body, including the skin, uterus, mouth and gastrointestinal tract. In fact it is estimated that there are more bacteria than cells in the human body, thus it is not surprising that studies have shown the microbiome has a significant impact on physical and even mental health. We have so much interdependence with the bacteria living on or in us, some studies have shown that the species composition of the gut microbiome is associated with many diseases, from cancer to metabolic syndrome. There is crosstalk between our body and the microbiome, our lifestyles and habits can alter the communities of our microbiome; their diversity and composition in turn affect our health.</p>
<p>Although I’m currently working as a forensic scientist, my graduate research was on microbiology so I am quite interested in the correlation between the  composition of an individual’s stool microbiome and their physical status, especially any genus/species of bacteria that are important for the prediction of obesity. This would be a good opportunity to practice my analytics skills too, since I don’t get to use them much in my day to day work too.</p>
<p>The dataset I’m using is a human metagenomics dataset from Kaggle which can be found <a class="reference external" href="https://www.kaggle.com/antaresnyc/human-metagenomics?select=abundance_stoolsubset.csv">here</a>. Credits for the data go to the original authors of the study and Kaggle user Alexey Kotlik who uploaded it.</p>
<p><sub> All code cells are hidden by default, click on the button to display them </sub></p>
<section id="data-cleaning-and-explorations">
<h1>Data cleaning and explorations<a class="headerlink" href="#data-cleaning-and-explorations" title="Permalink to this headline">#</a></h1>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">### import packages ###</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">re</span>

<span class="c1">### import raw data</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;metagenomics/abundance_stoolsubset.csv&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;str&#39;</span><span class="p">)</span>
<span class="n">cols</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">columns</span>

<span class="k">def</span> <span class="nf">warn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">pass</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">warn</span> <span class="o">=</span> <span class="n">warn</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s take a look at the raw data</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;sample dimensions are </span><span class="si">{}</span><span class="s1"> rows by </span><span class="si">{}</span><span class="s1"> columns&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">()</span>
<span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>sample dimensions are 1989 rows by 2339 columns
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>dataset_name</th>
      <th>sampleID</th>
      <th>subjectID</th>
      <th>bodysite</th>
      <th>disease</th>
      <th>age</th>
      <th>gender</th>
      <th>country</th>
      <th>sequencing_technology</th>
      <th>pubmedid</th>
      <th>...</th>
      <th>k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactobacillales|f__Enterococcaceae|g__Enterococcus|s__Enterococcus_gilvus|t__Enterococcus_gilvus_unclassified</th>
      <th>k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactobacillales|f__Lactobacillaceae|g__Lactobacillus|s__Lactobacillus_otakiensis</th>
      <th>k__Bacteria|p__Firmicutes|c__Bacilli|o__Lactobacillales|f__Lactobacillaceae|g__Lactobacillus|s__Lactobacillus_otakiensis|t__GCF_000415925</th>
      <th>k__Bacteria|p__Firmicutes|c__Clostridia|o__Clostridiales|f__Peptococcaceae</th>
      <th>k__Bacteria|p__Firmicutes|c__Clostridia|o__Clostridiales|f__Peptococcaceae|g__Desulfotomaculum</th>
      <th>k__Bacteria|p__Firmicutes|c__Clostridia|o__Clostridiales|f__Peptococcaceae|g__Desulfotomaculum|s__Desulfotomaculum_ruminis</th>
      <th>k__Bacteria|p__Firmicutes|c__Clostridia|o__Clostridiales|f__Peptococcaceae|g__Desulfotomaculum|s__Desulfotomaculum_ruminis|t__GCF_000215085</th>
      <th>k__Bacteria|p__Firmicutes|c__Clostridia|o__Clostridiales|f__Ruminococcaceae|g__Faecalibacterium|s__Faecalibacterium_prausnitzii|t__GCF_000209855</th>
      <th>k__Bacteria|p__Firmicutes|c__Negativicutes|o__Selenomonadales|f__Veillonellaceae|g__Megasphaera|s__Megasphaera_sp_BV3C16_1</th>
      <th>k__Bacteria|p__Firmicutes|c__Negativicutes|o__Selenomonadales|f__Veillonellaceae|g__Megasphaera|s__Megasphaera_sp_BV3C16_1|t__GCF_000478965</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Candela_Africa</td>
      <td>H10</td>
      <td>h10</td>
      <td>stool</td>
      <td>n</td>
      <td>40</td>
      <td>female</td>
      <td>tanzania</td>
      <td>Illumina</td>
      <td>25981789</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Candela_Africa</td>
      <td>H11</td>
      <td>h11</td>
      <td>stool</td>
      <td>n</td>
      <td>29</td>
      <td>female</td>
      <td>tanzania</td>
      <td>Illumina</td>
      <td>25981789</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 2339 columns</p>
</div></div></div>
</div>
<p>This dataset is pretty high dimensional with 2339 columns, but most of the columns are not really relevant to what I’m doing. Gender, age and country is available too, which gives me an idea to try something similar to this but see if I can differentiate gender or location based on microbiome. But that’ll be something for the future.</p>
<p>Since I’m interested in obesity, I’ll filter for that data with indicators of obesity and normal weight individuals. I got my BMI categories here from <a class="reference external" href="https://www.nhlbi.nih.gov/health/educational/lose_wt/BMI/bmicalc.htm">NIH</a>, which is:</p>
<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}
</style>
<table class="tg">
<thead>
  <tr>
    <th class="tg-c3ow">Underweight</th>
    <th class="tg-c3ow">&lt;18.5</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-c3ow">Normal weight</td>
    <td class="tg-c3ow">18.5-24.9</td>
  </tr>
  <tr>
    <td class="tg-c3ow">Overweight</td>
    <td class="tg-c3ow">25-29.9</td>
  </tr>
  <tr>
    <td class="tg-c3ow">Obesity</td>
    <td class="tg-c3ow">&gt;=30</td>
  </tr>
</tbody>
</table><p>In the cell below, I drop the columns which I won’t be using, except for some that identifies where the sample is from. I won’t be using data from individuals with other diseases, only those who are healthy or obese, so as to not add any confounding variables or other complications in the modeling.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">### preprocess data ###</span>

<span class="c1"># filter for categories of interest</span>

<span class="n">processed</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;disease&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">([</span><span class="s1">&#39;obesity&#39;</span><span class="p">,</span> <span class="s1">&#39;obese&#39;</span><span class="p">,</span> <span class="s1">&#39;overweight&#39;</span><span class="p">,</span><span class="s1">&#39;leaness&#39;</span><span class="p">,</span> <span class="s1">&#39;n&#39;</span><span class="p">])]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="c1"># drop columns that are not needed</span>
<span class="n">to_drop</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">cols</span><span class="p">[</span><span class="mi">2</span><span class="p">:</span><span class="mi">4</span><span class="p">])</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">cols</span><span class="p">[</span><span class="mi">8</span><span class="p">:</span><span class="mi">20</span><span class="p">])</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">cols</span><span class="p">[</span><span class="mi">21</span><span class="p">:</span><span class="mi">211</span><span class="p">])</span>
<span class="n">processed</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="n">to_drop</span><span class="p">,</span> <span class="n">inplace</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

<span class="c1"># remove samples without bmi, convert bmi and abundance to float and filter for regular weight and obese</span>
<span class="n">processed</span> <span class="o">=</span> <span class="n">processed</span><span class="p">[</span><span class="o">~</span><span class="n">processed</span><span class="p">[</span><span class="s1">&#39;bmi&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">([</span><span class="s1">&#39;na&#39;</span><span class="p">,</span> <span class="s1">&#39;nd&#39;</span><span class="p">])]</span>

<span class="n">processed</span><span class="p">[</span><span class="s1">&#39;bmi&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_numeric</span><span class="p">(</span><span class="n">processed</span><span class="p">[</span><span class="s1">&#39;bmi&#39;</span><span class="p">],</span> <span class="n">downcast</span> <span class="o">=</span><span class="s1">&#39;float&#39;</span><span class="p">)</span>

<span class="c1"># processed.iloc[:, 7:] = processed.iloc[:, 7:].apply(pd.to_numeric)</span>

<span class="n">processed</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">7</span><span class="p">:]</span> <span class="o">=</span> <span class="n">processed</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">7</span><span class="p">:]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="c1"># create labels for classification</span>

<span class="n">bmi</span> <span class="o">=</span> <span class="p">[(</span><span class="n">processed</span><span class="p">[</span><span class="s1">&#39;bmi&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mf">18.5</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">processed</span><span class="p">[</span><span class="s1">&#39;bmi&#39;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">25</span><span class="p">),</span> <span class="p">(</span><span class="n">processed</span><span class="p">[</span><span class="s1">&#39;bmi&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">25</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">processed</span><span class="p">[</span><span class="s1">&#39;bmi&#39;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">30</span><span class="p">),</span> <span class="n">processed</span><span class="p">[</span><span class="s1">&#39;bmi&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">30</span> <span class="p">]</span>

<span class="n">categories</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;1&#39;</span><span class="p">,</span><span class="s1">&#39;2&#39;</span><span class="p">,</span><span class="s1">&#39;3&#39;</span><span class="p">]</span>

<span class="n">classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">bmi</span><span class="p">,</span> <span class="n">categories</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="s1">&#39;0&#39;</span><span class="p">)</span>

<span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">classes</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(array([&#39;0&#39;, &#39;1&#39;, &#39;2&#39;, &#39;3&#39;], dtype=&#39;&lt;U1&#39;),
 array([ 35, 444, 177, 309], dtype=int64))
</pre></div>
</div>
</div>
</div>
<p>There are too little observations for underweight data, which will affect the modeling accuracy. Since I’m curious about the microbiome composition of regular and obese individuals (classes 1 and 3), I’ll just drop the classes I’m not interested in rather than getting bogged down in dealing with the data imbalance.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bmi</span> <span class="o">=</span> <span class="p">[(</span><span class="n">processed</span><span class="p">[</span><span class="s1">&#39;bmi&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mf">18.5</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">processed</span><span class="p">[</span><span class="s1">&#39;bmi&#39;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">25</span><span class="p">),</span> <span class="n">processed</span><span class="p">[</span><span class="s1">&#39;bmi&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">30</span> <span class="p">]</span>

<span class="n">categories</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;0&#39;</span><span class="p">,</span><span class="s1">&#39;1&#39;</span><span class="p">]</span>

<span class="n">processed</span><span class="p">[</span><span class="s1">&#39;bmi_category&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">bmi</span><span class="p">,</span> <span class="n">categories</span><span class="p">,</span> <span class="n">default</span> <span class="o">=</span> <span class="s1">&#39;2&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>I also noticed some “redundancy” in the relative abdundance data which should be removed after the initial data cleaning:</p>
<p>The relative abundance for every species is recorded multiple times in the data, as an example, let’s look at the data for Archaea bacteria for the <span class="math notranslate nohighlight">\(6^{th}\)</span> observation</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">processed</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">:</span><span class="mi">16</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>k__Archaea                                                                                                                                                                                     0.4308
k__Archaea|p__Euryarchaeota                                                                                                                                                                    0.4308
k__Archaea|p__Euryarchaeota|c__Methanobacteria                                                                                                                                                 0.4308
k__Archaea|p__Euryarchaeota|c__Methanobacteria|o__Methanobacteriales                                                                                                                           0.4308
k__Archaea|p__Euryarchaeota|c__Methanobacteria|o__Methanobacteriales|f__Methanobacteriaceae                                                                                                    0.4308
k__Archaea|p__Euryarchaeota|c__Methanobacteria|o__Methanobacteriales|f__Methanobacteriaceae|g__Methanobrevibacter                                                                              0.4308
k__Archaea|p__Euryarchaeota|c__Methanobacteria|o__Methanobacteriales|f__Methanobacteriaceae|g__Methanobrevibacter|s__Methanobrevibacter_smithii                                                0.3816
k__Archaea|p__Euryarchaeota|c__Methanobacteria|o__Methanobacteriales|f__Methanobacteriaceae|g__Methanobrevibacter|s__Methanobrevibacter_smithii|t__Methanobrevibacter_smithii_unclassified     0.3816
k__Archaea|p__Euryarchaeota|c__Methanobacteria|o__Methanobacteriales|f__Methanobacteriaceae|g__Methanobrevibacter|s__Methanobrevibacter_unclassified                                          0.04919
Name: 43, dtype: object
</pre></div>
</div>
</div>
</div>
<p>The first letter of the name of columns stands for taxonomic rank. For example, in the output above, the first row (col 7), “k_Archaea”, is for the kingdom of <a class="reference external" href="https://en.wikipedia.org/wiki/Archaea">Archaea</a> and sum abundance of all bacteria from this kingdom is 0.4308. Row 2, “k_Archaea|p_Euryarchaeota” is referring to the phylum of Euryarchaeota within the Archaea kingdom. (See <a class="reference external" href="https://en.wikipedia.org/wiki/Bacterial_taxonomy">Bacteria Taxonomy</a>). Since I’m interested at the species, I’ll be removing columns of other taxonomic ranks. Notice that for Methanobrevibacter smithii, there is an even lower rank which starts with “t” which refers to type, however not every species in the dataset has a type, I’ll stop at the species level.</p>
<p>We can see that for this data point, only 2 species were detected, <em>M.smithii</em> and a unclassified methanobrevibacter, at 0.3816 and 0.04919 abundance respectively. And both values add up to 0.4308, which confirms that I’m not reading the data wrong.</p>
<p>I’ll use regex to find column names that contain species level abundance and filter the other columns. And since I’m already filtering at the species level anyways, I’m quite curious to study genus level data as well, so I’ll filter for those too. But different species of bacteria within the same genus can have different biochemistry and life cycles, so it is likely that genus will not be as good a predictor.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># get names of all columns that contain abundance data</span>
<span class="n">bacteria</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">processed</span><span class="o">.</span><span class="n">columns</span><span class="p">)[</span><span class="mi">7</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># use regex to select exclusively for columns that contain species level abundance</span>

<span class="c1"># filters for species level</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;(\|s__\w+$)&#39;</span><span class="p">)</span>

<span class="c1"># filter for genus level</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\|g__\w+$&#39;</span><span class="p">)</span>


<span class="n">not_species</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">bacteria</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">s</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span>
<span class="n">not_genus</span> <span class="o">=</span> <span class="p">[</span><span class="n">j</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">bacteria</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">g</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">j</span><span class="p">)]</span>

<span class="c1"># drop columns that are not needed</span>
<span class="n">species_data</span> <span class="o">=</span> <span class="n">processed</span><span class="p">[</span><span class="n">processed</span><span class="p">[</span><span class="s1">&#39;bmi_category&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="s1">&#39;2&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="n">not_species</span><span class="p">)</span>

<span class="n">genus_data</span> <span class="o">=</span> <span class="n">processed</span><span class="p">[</span><span class="n">processed</span><span class="p">[</span><span class="s1">&#39;bmi_category&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="s1">&#39;2&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="n">not_genus</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;New dimensions of the dataset:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Species level dataset: </span><span class="si">{}</span><span class="s1"> rows by </span><span class="si">{}</span><span class="s1"> cols&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">species_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">species_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Genus level dataset: </span><span class="si">{}</span><span class="s1"> rows by </span><span class="si">{}</span><span class="s1"> cols&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">genus_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">genus_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>New dimensions of the dataset:

Species level dataset: 753 rows by 834 cols

Genus level dataset: 753 rows by 300 cols
</pre></div>
</div>
</div>
</div>
<p>Next is to shorten the feature names into something more readable:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># rename feature names to shorter ones for species</span>

<span class="n">s</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;s__(\w+)&#39;</span><span class="p">)</span>

<span class="n">short</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">species_data</span><span class="p">)[</span><span class="mi">7</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
    <span class="n">short</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">))</span>
    
<span class="n">new</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">species_data</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">species_data</span><span class="p">)[:</span><span class="mi">7</span><span class="p">]</span> <span class="o">+</span> <span class="n">short</span><span class="p">))</span>

<span class="n">species_data</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="n">new</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># same thing for genus</span>

<span class="n">g</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;g__(\w+)&#39;</span><span class="p">)</span>

<span class="n">short</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">genus_data</span><span class="p">)[</span><span class="mi">7</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
    <span class="n">short</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">,</span> <span class="s2">&quot; &quot;</span><span class="p">))</span>
    
<span class="n">new</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">genus_data</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">genus_data</span><span class="p">)[:</span><span class="mi">7</span><span class="p">]</span> <span class="o">+</span> <span class="n">short</span><span class="p">))</span>

<span class="n">genus_data</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="n">new</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now to do a check on the data, first for missing values. Also, since this is a relative abundance dataset, the total values in each observation should add up to 100:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># quick and dirty missing value check</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;there are </span><span class="si">{}</span><span class="s1"> missing values in species and </span><span class="si">{}</span><span class="s1"> in genus.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">species_data</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span> <span class="n">genus_data</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>there are 0 missing values in species and 0 in genus.
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># a list to collect index of observations that add up to 0 or more than 100</span>
<span class="n">gt</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">lt</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">species_data</span><span class="p">)):</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">species_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">7</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">100</span><span class="p">):</span>
        <span class="n">gt</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">species_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">7</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mi">100</span><span class="p">:</span>
        <span class="n">lt</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1"> observations &gt;100</span><span class="si">% a</span><span class="s1">nd </span><span class="si">{}</span><span class="s1"> observations &lt;100% to check&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">gt</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">lt</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>105 observations &gt;100% and 627 observations &lt;100% to check
</pre></div>
</div>
</div>
</div>
<p>That’s a lot of observations with issues, let’s take a look at those that add up to less than 100 first.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">lt</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;row </span><span class="si">{}</span><span class="s1">, total abundance </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lt</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">species_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">lt</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="mi">7</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>row 625, total abundance 99.99992370605469
row 205, total abundance 99.89722442626953
row 734, total abundance 99.99999237060547
row 732, total abundance 99.9927749633789
row 656, total abundance 99.04145050048828
row 522, total abundance 99.9999771118164
row 585, total abundance 99.90008544921875
row 604, total abundance 99.9999771118164
row 451, total abundance 99.9739990234375
row 613, total abundance 99.96712493896484
</pre></div>
</div>
</div>
</div>
<p>And those that add up to more than 100</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">gt</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;row </span><span class="si">{}</span><span class="s1">, total abundance </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gt</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">species_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">gt</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="mi">7</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>row 398, total abundance 100.00000762939453
row 472, total abundance 100.00003814697266
row 132, total abundance 100.00000762939453
row 437, total abundance 100.00003814697266
row 386, total abundance 100.00000762939453
row 484, total abundance 100.0000228881836
row 119, total abundance 100.00005340576172
row 400, total abundance 100.00000762939453
row 639, total abundance 100.0000228881836
row 459, total abundance 100.00005340576172
</pre></div>
</div>
</div>
</div>
<p>It seems like the issue is due to floating point imprecision or rounding errors, it shouldn’t affect the modeling then.</p>
<p>Now that I’m happy with the state of the data, let’s take a deeper look into the data.</p>
<p>First let’s look at the correlation between the variables and the classes. In this case, I’m looking for correlation between dichotomous categorical variables, the 2 classes and continuous variables which are not normally distributed. (In case you were wondering, my earlier explorations into the data showed me the data is mostly sparse and not normally distributed.) So in this case, I use the Mann-Whitney U test and calculate <a class="reference external" href="https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test#Rank-biserial_correlation">rank-biserial correlation</a> for class and each species of bacteria.</p>
<p>The logic that I’m working on here, is that species with high correlation to the dependent variable should have a significant difference in their distribution between the classes, which I can hopefully visualise in a histograms. Since there are so many species, I’ll put the correlation on a scatterplot and then the distributions of the 10 species with the highest correlation to obesity and normal weight.</p>
<p>The dataset is quite sparse and widely spread, so I’ll have to plot on a <span class="math notranslate nohighlight">\(log_{10}\)</span> scale for visualisation. Since the sparsity will then give me problems, what I’ll do is add 0.00001 to the data before plotting them, so note that <span class="math notranslate nohighlight">\(10^{-5}\)</span> on the x-axis simply means the abundance is 0%.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">calculate_mann_whitney</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">column_name</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Calculates mann_whitney U rank test rank-biserial correlation</span>
<span class="sd">    Assumes the data has only 2 classes, 1 and 0</span>
<span class="sd">    and the last column contains the classes&#39;&#39;&#39;</span>

    <span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">mannwhitneyu</span>
    
    <span class="c1"># dictionary to collect data</span>
    <span class="n">variables</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">class0</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">i</span><span class="p">]][</span><span class="n">df</span><span class="p">[</span><span class="n">column_name</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;0&#39;</span><span class="p">]</span>
        <span class="n">class1</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">i</span><span class="p">]][</span><span class="n">df</span><span class="p">[</span><span class="n">column_name</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;1&#39;</span><span class="p">]</span>

        <span class="n">u</span> <span class="o">=</span> <span class="n">mannwhitneyu</span><span class="p">(</span><span class="n">class0</span><span class="p">,</span> <span class="n">class1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># the calculation of rank-biserial correlation changes depending on whether the test statistic, U, is the smaller one</span>
        <span class="c1"># since scipy always returns the test statistic of the first argument, rather than do 2 Mann-Whitney tests to get</span>
        <span class="c1"># both U1 and U2 to compare. I&#39;ll just stick to one calculation and absolute it to get the correlation regardless</span>
        <span class="c1"># of whether U is larger or smaller </span>
        <span class="n">variables</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">absolute</span><span class="p">((</span><span class="mi">2</span> <span class="o">*</span> <span class="n">u</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">class0</span><span class="p">)</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">class1</span><span class="p">))</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">variables</span><span class="p">,</span> <span class="n">orient</span><span class="o">=</span><span class="s1">&#39;index&#39;</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;rank_biserial&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input tag_full-width docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">species_mann</span> <span class="o">=</span> <span class="n">calculate_mann_whitney</span><span class="p">(</span><span class="n">species_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">7</span><span class="p">:],</span> <span class="s1">&#39;bmi_category&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">6</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">species_mann</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="s1">&#39;rank_biserial&#39;</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="n">species_mann</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Correlation&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">ticks</span> <span class="o">=</span> <span class="p">[])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>([], [])
</pre></div>
</div>
<img alt="_images/Project_26_1.png" src="_images/Project_26_1.png" />
</div>
</div>
<div class="cell tag_hide-input tag_full-width tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>

<span class="n">topSP</span> <span class="o">=</span> <span class="n">species_mann</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s1">&#39;rank_biserial&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">values</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>

<span class="n">top_subset</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([(</span><span class="n">species_data</span><span class="p">[</span><span class="n">topSP</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.00001</span><span class="p">),</span> <span class="n">species_data</span><span class="p">[</span><span class="s1">&#39;bmi_category&#39;</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span> <span class="n">top_subset</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="n">topSP</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;bmi_category&#39;</span><span class="p">,</span> <span class="n">log_scale</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="c1"># plt.xlim(left = 0.001)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Relative abundance of species with highest correlation (descending)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Project_27_0.png" src="_images/Project_27_0.png" />
</div>
</div>
<p>With the exception of the first two, I’m not seeing any major differences in the distributions of obese and normal-weight observations in the plots. This is not entirely unexpected, since I don’t expect a single species to contain much information on whether an individual is obese or not, unless it is some bacteria that grows only in obese individuals and not regular individuals or vice versa. I doubt anything like that ever happens, since being overweight/obese itself is a spectrum, not some condition with a yes/no hard cutoff. And we can see here that for many species of bacteria, the relative abundance is 0 for many observations as I mentioned earlier.</p>
<p>But let’s move on the next part and see if feature importance of the best model will coincide with these 10 species.</p>
<p>I intend to use classification accuracy to evaluate the models and find the best one. As a start, I like to use log regression as a baseline model and if it performs well, the coefficients become useful measures of importance. That said, I’m expecting the non-parametric or ensemble models to perform better, so I’m prepared to use other methods to determine feature importance.</p>
<p>The models I’ll try are:</p>
<ol class="simple">
<li><p>Logistic regression</p></li>
<li><p>PLS-DA</p></li>
<li><p>SVM</p></li>
<li><p>Random Forest</p></li>
<li><p>Adaboost</p></li>
<li><p>Gradient Boost</p></li>
</ol>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">RandomizedSearchCV</span><span class="p">,</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">balanced_accuracy_score</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">species_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">7</span><span class="p">:</span><span class="n">species_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">species_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># split data into train and test sets</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">77</span><span class="p">)</span>

<span class="c1"># scale data based on training set</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># simple function to output the performance metrics of a model</span>

<span class="k">def</span> <span class="nf">model_performance</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;prints model metrics&#39;&#39;&#39;</span>
    <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">ConfusionMatrixDisplay</span><span class="p">,</span> <span class="n">classification_report</span>

    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">dpi</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

    <span class="n">ConfusionMatrixDisplay</span><span class="o">.</span><span class="n">from_predictions</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">fig</span><span class="o">.</span><span class="n">gca</span><span class="p">(),</span> <span class="n">display_labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;normal&#39;</span><span class="p">,</span><span class="s1">&#39;obese&#39;</span><span class="p">])</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
    <span class="c1"># print(&#39;balanced accuracy: {0:.4g}&#39;.format(metrics.balance_accuracy_score(y_true, y_pred)))</span>


<span class="c1"># and another one to collate the scores</span>
<span class="k">def</span> <span class="nf">model_comparison</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">names</span><span class="p">,</span> <span class="n">x_test1</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">pls</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Returns a dataframe of various classification metrics</span>

<span class="sd">    Parameters: </span>
<span class="sd">    models: trained models</span>
<span class="sd">    names: names for models in dataframe</span>
<span class="sd">    x_test1: test data</span>
<span class="sd">    y_test: test classes</span>
<span class="sd">    pls: pls model, which is used to transform x_test before prediction</span>
<span class="sd">    </span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">models</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">names</span><span class="p">),</span> <span class="s2">&quot;number of models and names is not the same&quot;</span>

    <span class="n">model_scores</span> <span class="o">=</span> <span class="p">{}</span>
   
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">names</span><span class="p">)):</span>
        
        <span class="n">temp</span> <span class="o">=</span> <span class="p">{}</span>
        
        <span class="k">if</span> <span class="p">(</span><span class="n">names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;PLS-DA&#39;</span><span class="p">)</span> <span class="p">:</span>
            <span class="n">x_test</span> <span class="o">=</span> <span class="n">pls</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x_test1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test1</span>

        <span class="n">temp</span><span class="p">[</span><span class="s1">&#39;Balanced Accuracy&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">balanced_accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">models</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">))</span>
        <span class="n">temp</span><span class="p">[</span><span class="s1">&#39;ROC AUC&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">models</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">object</span><span class="p">))</span>
        <span class="n">temp</span><span class="p">[</span><span class="s1">&#39;Precision 1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">models</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">),</span> <span class="n">pos_label</span> <span class="o">=</span> <span class="s1">&#39;1&#39;</span><span class="p">)</span>
        <span class="n">temp</span><span class="p">[</span><span class="s1">&#39;Precision 0&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">models</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">),</span> <span class="n">pos_label</span> <span class="o">=</span> <span class="s1">&#39;0&#39;</span><span class="p">)</span>
        <span class="n">temp</span><span class="p">[</span><span class="s1">&#39;Recall 1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">models</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">),</span> <span class="n">pos_label</span> <span class="o">=</span> <span class="s1">&#39;1&#39;</span><span class="p">)</span>
        <span class="n">temp</span><span class="p">[</span><span class="s1">&#39;Recall 0&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">models</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">),</span> <span class="n">pos_label</span> <span class="o">=</span> <span class="s1">&#39;0&#39;</span><span class="p">)</span>

        <span class="c1"># create a dictionary for the current model</span>
        <span class="n">model_scores</span><span class="p">[</span><span class="n">names</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="n">temp</span>


        <span class="c1">#tabulate metrics</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">model_scores</span><span class="p">,</span> <span class="n">orient</span><span class="o">=</span><span class="s1">&#39;index&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="logistic-regression">
<h1>Logistic regression<a class="headerlink" href="#logistic-regression" title="Permalink to this headline">#</a></h1>
<p>Since the species dataset has more variables than observations, some degree of regularisation will be necessary for a good fit.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">uniform</span><span class="p">,</span> <span class="n">norm</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set_theme</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">)</span>

<span class="n">log_params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="n">uniform</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">20.0</span><span class="p">),</span> <span class="n">penalty</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span> <span class="s1">&#39;l2&#39;</span><span class="p">])</span>

<span class="c1"># fit log regression</span>
<span class="n">log_reg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">78</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;liblinear&#39;</span><span class="p">)</span>

<span class="c1"># randomized hyperparameter search</span>
<span class="n">log_reg_CV</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span><span class="n">log_reg</span><span class="p">,</span> <span class="n">log_params</span><span class="p">,</span> <span class="n">n_iter</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">78</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="s1">&#39;balanced_accuracy&#39;</span><span class="p">,</span> <span class="n">refit</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">log_reg_CV</span><span class="o">.</span><span class="n">best_params_</span>

<span class="n">model_performance</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">log_reg_CV</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

           0       0.83      0.89      0.86        89
           1       0.82      0.74      0.78        62

    accuracy                           0.83       151
   macro avg       0.83      0.81      0.82       151
weighted avg       0.83      0.83      0.83       151
</pre></div>
</div>
<img alt="_images/Project_33_1.png" src="_images/Project_33_1.png" />
</div>
</div>
</section>
<section id="partial-least-squares-discriminant-analysis">
<h1>Partial least squares discriminant analysis<a class="headerlink" href="#partial-least-squares-discriminant-analysis" title="Permalink to this headline">#</a></h1>
<p>I learnt about this method a couple of weeks back and was quite interested in trying it out. I simply couldn’t get pipeline working, so I just used a loop instead for optimisation.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cross_decomposition</span> <span class="kn">import</span> <span class="n">PLSRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.discriminant_analysis</span> <span class="kn">import</span> <span class="n">LinearDiscriminantAnalysis</span>

<span class="n">n_components</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">score</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">82</span><span class="p">,</span><span class="mi">4</span><span class="p">):</span>

    <span class="c1"># pls model</span>
    <span class="n">plsR</span> <span class="o">=</span> <span class="n">PLSRegression</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="c1"># use components for LDA</span>
    <span class="n">lda</span> <span class="o">=</span> <span class="n">LinearDiscriminantAnalysis</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">plsR</span><span class="o">.</span><span class="n">x_scores_</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="n">n_components</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
    <span class="n">score</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">balanced_accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">lda</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">plsR</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x_test</span><span class="p">))))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">n_components</span><span class="p">,</span> <span class="n">score</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;no. of components for best score: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n_components</span><span class="p">[</span><span class="n">score</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">score</span><span class="p">))]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>no. of components for best score: 6
</pre></div>
</div>
<img alt="_images/Project_35_1.png" src="_images/Project_35_1.png" />
</div>
</div>
<div class="cell tag_hide-input tag_full-width docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plsR</span> <span class="o">=</span> <span class="n">PLSRegression</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">lda</span> <span class="o">=</span> <span class="n">LinearDiscriminantAnalysis</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">plsR</span><span class="o">.</span><span class="n">x_scores_</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">model_performance</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">lda</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">plsR</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x_test</span><span class="p">)))</span>

<span class="c1"># to look at the species with highest absolute loadings</span>
<span class="c1">#species_data.columns[np.argsort(np.absolute(plsR.x_loadings_[:, 0]))[:10]]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

           0       0.82      0.83      0.83        89
           1       0.75      0.74      0.75        62

    accuracy                           0.79       151
   macro avg       0.79      0.79      0.79       151
weighted avg       0.79      0.79      0.79       151
</pre></div>
</div>
<img alt="_images/Project_36_1.png" src="_images/Project_36_1.png" />
</div>
</div>
<p>The PLS-DA model appears to be comparable to the log regression model</p>
</section>
<section id="a-little-experiment">
<h1><em>a little experiment ….</em><a class="headerlink" href="#a-little-experiment" title="Permalink to this headline">#</a></h1>
<p>This idea actually occurred to me when I was almost done with this project, but since it involves logistic regression, I think it fits better here. Recall that I calculated the rank-biserial correlation earlier in this notebook, <em>what if I use the rank-biseral correlation as a form of feature selection?</em> I’ll try to use features that have correlation != 0 in the logistic regression, if anything, it may improve the model it reduces the number of features.</p>
<p>To account for the possibility of any improvements (or degradations) in accuracy, I’ll also build 3 logistic regression models where I randomly pick the same number of features and compare their accuracies.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># get indices of features with correlation </span>

<span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">species_mann</span> <span class="o">!=</span> <span class="mf">0.0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> features with non-zero rank-biserial correlation&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">idx</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>609 features with non-zero rank-biserial correlation
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># everything stays the same, except training and test data dimension is now reduced</span>

<span class="n">log_params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="n">uniform</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">20.0</span><span class="p">),</span> <span class="n">penalty</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span> <span class="s1">&#39;l2&#39;</span><span class="p">])</span>

<span class="c1"># fit log regression</span>
<span class="n">rank_log_reg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">78</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;liblinear&#39;</span><span class="p">)</span>

<span class="c1"># randomized hyperparameter search</span>
<span class="n">rank_log_reg_CV</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span><span class="n">rank_log_reg</span><span class="p">,</span> <span class="n">log_params</span><span class="p">,</span> <span class="n">n_iter</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">78</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="s1">&#39;balanced_accuracy&#39;</span><span class="p">,</span> <span class="n">refit</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">[:,</span> <span class="n">idx</span><span class="p">],</span> <span class="n">y_train</span><span class="p">)</span>


<span class="c1"># random feature selection</span>

<span class="n">rand_idx</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">609</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)]</span>

<span class="n">rand_log_params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="n">uniform</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">20.0</span><span class="p">),</span> <span class="n">penalty</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span> <span class="s1">&#39;l2&#39;</span><span class="p">])</span>

<span class="c1"># fit log regression</span>
<span class="n">rand_log</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">78</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;liblinear&#39;</span><span class="p">)</span>

<span class="n">rand_acc</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">rand_idx</span><span class="p">:</span>
    <span class="n">rand_log_CV</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span><span class="n">rand_log</span><span class="p">,</span> <span class="n">rand_log_params</span><span class="p">,</span> <span class="n">n_iter</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">78</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="s1">&#39;balanced_accuracy&#39;</span><span class="p">,</span> <span class="n">refit</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">rand_acc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">balanced_accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">rand_log_CV</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])))</span>


<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;average difference in accuracy: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">balanced_accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">rank_log_reg_CV</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">[:,</span> <span class="n">idx</span><span class="p">]))</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">rand_acc</span><span class="p">))))</span>
</pre></div>
</div>
</div>
</div>
<p>There are some differences in the performance, but not a huge difference or anything. Let’s take a look at the metrics and confusion matrix for the rank-biserial model</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_performance</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">rank_log_reg_CV</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">[:,</span> <span class="n">idx</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

           0       0.83      0.89      0.86        89
           1       0.82      0.74      0.78        62

    accuracy                           0.83       151
   macro avg       0.83      0.81      0.82       151
weighted avg       0.83      0.83      0.83       151
</pre></div>
</div>
<img alt="_images/Project_42_1.png" src="_images/Project_42_1.png" />
</div>
</div>
<p>It seems like there isn’t any improvement to the accuracy, in fact, both the baseline logistic regression model and this one has similar metrics and confusion matrix. It’s probably because the regularisation in both models ended up choosing the same predictors.</p>
<p>I’d was thinking this might be a good way to some preliminary feature selection, too bad my stroke of brilliance didn’t turn out brilliantly.</p>
<p>(pun intended)</p>
</section>
<section id="kernel-svm">
<h1>Kernel SVM<a class="headerlink" href="#kernel-svm" title="Permalink to this headline">#</a></h1>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#step by step optimization</span>

<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>

<span class="n">svm_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;kernel&#39;</span><span class="p">:[</span><span class="s1">&#39;rbf&#39;</span><span class="p">,</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">,</span><span class="s1">&#39;poly&#39;</span><span class="p">],</span> <span class="s1">&#39;C&#39;</span><span class="p">:</span><span class="n">uniform</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">10</span><span class="p">)}</span>

<span class="n">svm</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">max_iter</span> <span class="o">=</span> <span class="mi">5000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">78</span><span class="p">)</span>

<span class="n">svm_cv</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span><span class="n">svm</span><span class="p">,</span> <span class="n">svm_params</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="s1">&#39;balanced_accuracy&#39;</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">78</span><span class="p">,</span> <span class="n">n_jobs</span> <span class="o">=</span> <span class="mi">6</span><span class="p">,</span> <span class="n">refit</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">svm_cv</span><span class="o">.</span><span class="n">best_params_</span>

<span class="n">model_performance</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">svm_cv</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

           0       0.83      0.89      0.86        89
           1       0.82      0.74      0.78        62

    accuracy                           0.83       151
   macro avg       0.83      0.81      0.82       151
weighted avg       0.83      0.83      0.83       151
</pre></div>
</div>
<img alt="_images/Project_45_1.png" src="_images/Project_45_1.png" />
</div>
</div>
</section>
<section id="random-forest">
<h1>Random Forest<a class="headerlink" href="#random-forest" title="Permalink to this headline">#</a></h1>
<p>I had tried decision trees as well, but didn’t get good performance so it wasn’t included.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">randint</span>

<span class="n">forest</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">78</span><span class="p">)</span>

<span class="n">forest_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span> <span class="s1">&#39;max_features&#39;</span><span class="p">:[</span><span class="s1">&#39;sqrt&#39;</span><span class="p">,</span><span class="s1">&#39;log2&#39;</span><span class="p">]}</span>

<span class="n">forest_cv</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span><span class="n">forest</span><span class="p">,</span> <span class="n">forest_params</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="s1">&#39;balanced_accuracy&#39;</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">78</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">refit</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">forest_cv</span><span class="o">.</span><span class="n">best_params_</span>

<span class="n">model_performance</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">forest_cv</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

           0       0.86      0.90      0.88        89
           1       0.84      0.79      0.82        62

    accuracy                           0.85       151
   macro avg       0.85      0.84      0.85       151
weighted avg       0.85      0.85      0.85       151
</pre></div>
</div>
<img alt="_images/Project_47_1.png" src="_images/Project_47_1.png" />
</div>
</div>
<p>The random forest model is the better performing one so far, which isn’t surprising, since an ensemble model like this one does have more flexibility to fit to the data better. Next let’s look at boosting</p>
</section>
<section id="adaboost">
<h1>Adaboost<a class="headerlink" href="#adaboost" title="Permalink to this headline">#</a></h1>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">AdaBoostClassifier</span>


<span class="n">ada</span> <span class="o">=</span> <span class="n">AdaBoostClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">78</span><span class="p">)</span>

<span class="n">ada_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">200</span><span class="p">)}</span>

<span class="n">ada_cv</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span><span class="n">ada</span><span class="p">,</span> <span class="n">ada_params</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="s1">&#39;balanced_accuracy&#39;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">78</span><span class="p">,</span> <span class="n">refit</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">model_performance</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">ada_cv</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

           0       0.87      0.92      0.90        89
           1       0.88      0.81      0.84        62

    accuracy                           0.87       151
   macro avg       0.87      0.86      0.87       151
weighted avg       0.87      0.87      0.87       151
</pre></div>
</div>
<img alt="_images/Project_49_1.png" src="_images/Project_49_1.png" />
</div>
</div>
</section>
<section id="gradient-boosting">
<h1>Gradient Boosting<a class="headerlink" href="#gradient-boosting" title="Permalink to this headline">#</a></h1>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingClassifier</span>

<span class="n">grad</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">78</span><span class="p">)</span>

<span class="n">grad_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">300</span><span class="p">)}</span>

<span class="n">grad_cv</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">grad_params</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">78</span><span class="p">,</span> <span class="n">refit</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">grad_cv</span><span class="o">.</span><span class="n">best_params_</span>

<span class="n">model_performance</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">grad_cv</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

           0       0.85      0.90      0.87        89
           1       0.84      0.77      0.81        62

    accuracy                           0.85       151
   macro avg       0.85      0.84      0.84       151
weighted avg       0.85      0.85      0.85       151
</pre></div>
</div>
<img alt="_images/Project_51_1.png" src="_images/Project_51_1.png" />
</div>
</div>
<p>It seems like the Adaboost and Gradient boost models have the best performance and are quite comparable. Now let’s take a look at metrics of the models.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">models</span> <span class="o">=</span> <span class="p">[</span><span class="n">log_reg_CV</span><span class="p">,</span> <span class="n">lda</span><span class="p">,</span> <span class="n">svm_cv</span><span class="p">,</span> <span class="n">forest_cv</span><span class="p">,</span> <span class="n">ada_cv</span><span class="p">,</span> <span class="n">grad_cv</span><span class="p">]</span>

<span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;log regression&#39;</span><span class="p">,</span> <span class="s1">&#39;PLS-DA&#39;</span><span class="p">,</span><span class="s1">&#39;kernel SVM&#39;</span><span class="p">,</span> <span class="s1">&#39;Random Forest&#39;</span><span class="p">,</span> <span class="s2">&quot;Adaboost&quot;</span><span class="p">,</span><span class="s1">&#39;Gradient Boost&#39;</span><span class="p">]</span>

<span class="n">model_comparison</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">names</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">plsR</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Balanced Accuracy</th>
      <th>ROC AUC</th>
      <th>Precision 1</th>
      <th>Precision 0</th>
      <th>Recall 1</th>
      <th>Recall 0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>log regression</th>
      <td>0.815</td>
      <td>0.815</td>
      <td>0.821</td>
      <td>0.832</td>
      <td>0.742</td>
      <td>0.888</td>
    </tr>
    <tr>
      <th>PLS-DA</th>
      <td>0.787</td>
      <td>0.787</td>
      <td>0.754</td>
      <td>0.822</td>
      <td>0.742</td>
      <td>0.831</td>
    </tr>
    <tr>
      <th>kernel SVM</th>
      <td>0.815</td>
      <td>0.815</td>
      <td>0.821</td>
      <td>0.832</td>
      <td>0.742</td>
      <td>0.888</td>
    </tr>
    <tr>
      <th>Random Forest</th>
      <td>0.845</td>
      <td>0.845</td>
      <td>0.845</td>
      <td>0.860</td>
      <td>0.790</td>
      <td>0.899</td>
    </tr>
    <tr>
      <th>Adaboost</th>
      <td>0.864</td>
      <td>0.864</td>
      <td>0.877</td>
      <td>0.872</td>
      <td>0.806</td>
      <td>0.921</td>
    </tr>
    <tr>
      <th>Gradient Boost</th>
      <td>0.837</td>
      <td>0.837</td>
      <td>0.842</td>
      <td>0.851</td>
      <td>0.774</td>
      <td>0.899</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Let’s take a look at the ROC and precision-recall plots as well. I’ll only plot the 3 best performing models in this case, no point complicating the graphs needlessly.</p>
<div class="cell tag_hide-input tag_output_scroll docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">models</span> <span class="o">=</span> <span class="p">[</span><span class="n">forest_cv</span><span class="p">,</span> <span class="n">ada_cv</span><span class="p">,</span> <span class="n">grad_cv</span><span class="p">]</span>

<span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Random Forest&#39;</span><span class="p">,</span> <span class="s2">&quot;Adaboost&quot;</span><span class="p">,</span><span class="s1">&#39;Gradient Boost&#39;</span><span class="p">]</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">names</span><span class="p">)):</span>

    <span class="n">metrics</span><span class="o">.</span><span class="n">plot_roc_curve</span><span class="p">(</span><span class="n">models</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">name</span> <span class="o">=</span> <span class="n">names</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;ROC&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span><span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;demibold&#39;</span><span class="p">)</span>
    <span class="c1"># ax[0].tick_params(axis=&#39;both&#39;, labelsize=14)</span>
    
    <span class="n">metrics</span><span class="o">.</span><span class="n">plot_precision_recall_curve</span><span class="p">(</span><span class="n">models</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">name</span> <span class="o">=</span> <span class="n">names</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Precision-Recall&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span><span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;demibold&#39;</span><span class="p">)</span>
    <span class="c1"># ax[1].tick_params(axis=&#39;both&#39;, labelsize=14)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Project_55_0.png" src="_images/Project_55_0.png" />
</div>
</div>
</section>
<section id="feature-importance">
<h1>feature importance<a class="headerlink" href="#feature-importance" title="Permalink to this headline">#</a></h1>
<p>The Adaboost classifier has the best accuracy and there’s even a built in <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier.feature_importances_">feature importance</a> measure! But impurity-based feature importance can be misleading, so the next option might be permutation importance. However, while permutation importance is useful, there are some things to take note of:</p>
<ol class="simple">
<li><p>The calculated permutation importance is literally for that model <em>only</em>, meaning that if I were to retrain the model with a different split of the data or even a different random state, the values can come out different.</p></li>
<li><p>Also, if two features are correlated, then the overall importance will be lowered since its split between the two.</p></li>
</ol>
<p>A good <a class="reference external" href="https://christophm.github.io/interpretable-ml-book/feature-importance.html">read</a> about permutation importance, some alternatives are given <a class="reference external" href="https://link.springer.com/article/10.1007/s11222-021-10057-z#Sec5">here</a>.</p>
<p>One of the alternatives suggested was leave-one-covariate-out (LOCO), which seems easy enough to implement. But I’m doing this analysis on a laptop and it’ll probably take it forever to do a k-fold LOCO analysis, so I won’t. I’ll just have to stick to permutation importance, unfortunately.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">### permutation importance ###</span>

<span class="kn">from</span> <span class="nn">sklearn.inspection</span> <span class="kn">import</span> <span class="n">permutation_importance</span>
  
<span class="n">perm_impt</span> <span class="o">=</span> <span class="n">permutation_importance</span><span class="p">(</span><span class="n">ada_cv</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;balanced_accuracy&#39;</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>

<span class="n">perm_idx</span> <span class="o">=</span> <span class="n">perm_impt</span><span class="o">.</span><span class="n">importances_mean</span><span class="o">.</span><span class="n">argsort</span><span class="p">()[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Top 10 species by feature importance (descending):&#39;</span><span class="p">)</span>

<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;species&#39;</span><span class="p">:</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">perm_idx</span><span class="p">][:</span><span class="mi">10</span><span class="p">],</span> <span class="s1">&#39;permutation importance&#39;</span><span class="p">:</span><span class="n">perm_impt</span><span class="o">.</span><span class="n">importances_mean</span><span class="p">[</span><span class="n">perm_idx</span><span class="p">][:</span><span class="mi">10</span><span class="p">]})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Top 10 species by feature importance (descending):
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>species</th>
      <th>permutation importance</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Streptococcus australis</td>
      <td>0.024239</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Lachnospiraceae bacterium 7 1 58FAA</td>
      <td>0.023922</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Roseburia intestinalis</td>
      <td>0.022771</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Faecalibacterium prausnitzii</td>
      <td>0.021502</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Barnesiella intestinihominis</td>
      <td>0.021013</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Klebsiella pneumoniae</td>
      <td>0.020723</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Actinomyces graevenitzii</td>
      <td>0.019744</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Bacteroides stercoris</td>
      <td>0.015857</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Oscillibacter unclassified</td>
      <td>0.015540</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Ruminococcus callidus</td>
      <td>0.015123</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell tag_hide-input tag_full-width docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>

<span class="n">impt_SP</span> <span class="o">=</span> <span class="n">species_data</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">7</span><span class="p">:][</span><span class="n">perm_idx</span><span class="p">[:</span><span class="mi">10</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span>

<span class="n">impt_subset</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([(</span><span class="n">species_data</span><span class="p">[</span><span class="n">impt_SP</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.00001</span><span class="p">),</span> <span class="n">species_data</span><span class="p">[</span><span class="s1">&#39;bmi_category&#39;</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span> <span class="n">impt_subset</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="n">impt_SP</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;bmi_category&#39;</span><span class="p">,</span> <span class="n">log_scale</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="c1"># plt.xlim(left = 0.001)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Project_58_0.png" src="_images/Project_58_0.png" />
</div>
</div>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Species with high rank-biserial correlation and permutation importance:&#39;</span><span class="p">)</span>

<span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">impt_SP</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">topSP</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Species with high rank-biserial correlation and permutation importance:
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;Lachnospiraceae bacterium 7 1 58FAA&#39;,
 &#39;Barnesiella intestinihominis&#39;,
 &#39;Klebsiella pneumoniae&#39;,
 &#39;Bacteroides stercoris&#39;]
</pre></div>
</div>
</div>
</div>
<p>4 species with high correlation to the classes also had high permutation importance in the Adaboost model. Visually, there appears to be some differences in the distribution of relative abundance of these bacteria in obese and normal weight stools, which is nice. Then again, I was specifically looking for bacteria species with these differences in my correlation analysis, so it’d be stranger if I didn’t.</p>
</section>
<section id="one-last-model">
<h1><em>one last model</em><a class="headerlink" href="#one-last-model" title="Permalink to this headline">#</a></h1>
<p>Finally, as a epilogue or maybe the cherry on top, I’d like to try using the Adaboost model but with data grouped at genus level, just to see if there are any differences.</p>
<p>Grouping the data at the genus level doesn’t cost too much in accuracy and the dimensions are reduced quite a bit, this might actually be be worth it in some situations.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">genus_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">7</span><span class="p">:</span><span class="n">genus_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">genus_data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># split data into train and test sets</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">878</span><span class="p">)</span>

<span class="c1"># scale data based on training set</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x_train</span><span class="p">)</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>

<span class="n">ada</span> <span class="o">=</span> <span class="n">AdaBoostClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">78</span><span class="p">)</span>

<span class="n">ada_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">200</span><span class="p">)}</span>

<span class="n">ada_cv</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span><span class="n">ada</span><span class="p">,</span> <span class="n">ada_params</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="s1">&#39;balanced_accuracy&#39;</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">78</span><span class="p">,</span> <span class="n">refit</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">model_performance</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">ada_cv</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>              precision    recall  f1-score   support

           0       0.85      0.83      0.84        83
           1       0.80      0.82      0.81        68

    accuracy                           0.83       151
   macro avg       0.83      0.83      0.83       151
weighted avg       0.83      0.83      0.83       151
</pre></div>
</div>
<img alt="_images/Project_61_1.png" src="_images/Project_61_1.png" />
</div>
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By The Jupyter Book community<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>