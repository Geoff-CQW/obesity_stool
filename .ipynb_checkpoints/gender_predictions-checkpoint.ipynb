{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('metagenomics/abundance_stoolsubset.csv', dtype='str')\n",
    "cols = data.columns\n",
    "\n",
    "# def warn(*args, **kwargs):\n",
    "#     pass\n",
    "# import warnings\n",
    "# warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['disease'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### preprocess data ###\n",
    "\n",
    "# filter for healthy samples without disease\n",
    "# processed = data[(data['gender'].isin(['male', 'female'])) & (data['disease'] == 'n')].copy()\n",
    "\n",
    "\n",
    "# filter for Type 2 diabetes and randomly select some controls then concatenate them and shuffle\n",
    "\n",
    "temp1 = data[data['disease'].isin(['t2d', 'impaired_glucose_tolerance'])].copy()\n",
    "# temp1 = data[data['disease'].isin(['cirrhosis'])].copy()\n",
    "\n",
    "processed = pd.concat([temp1, data[(data['disease'] == 'n')].sample(300)]).sample(frac=1).reset_index(drop = True)\n",
    "\n",
    "# drop columns that are not needed\n",
    "to_drop = list(cols[2:4]) + list(cols[8:20]) + list(cols[21:211])\n",
    "processed.drop(columns = to_drop, inplace = True)\n",
    "\n",
    "# 2nd filtering round\n",
    "\n",
    "bacteria = list(processed.columns)[7:]\n",
    "\n",
    "s = re.compile(r's__\\w+$')\n",
    "\n",
    "not_species = [i for i in bacteria if not s.search(i)]\n",
    "\n",
    "processed.drop(columns = not_species, inplace=True)\n",
    "\n",
    "\n",
    "# create a new column as labels\n",
    "processed['label'] = processed['disease'].apply(lambda x:  0 if (x == 'n') else 1)\n",
    "\n",
    "processed.reset_index(inplace=True, drop=True)\n",
    "\n",
    "species = processed.columns[7:833]\n",
    "\n",
    "processed[species] = processed[species].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename feature names to shorter one\n",
    "\n",
    "s = re.compile(r's__(\\w+)')\n",
    "\n",
    "short = []\n",
    "\n",
    "for i in list(species):\n",
    "    short.append( s.search(i).group(1).replace(\"_\", \" \"))\n",
    "    \n",
    "new = dict(zip(species, short))\n",
    "\n",
    "processed.rename(columns = new, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "x = processed.iloc[:, 7:833]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x = StandardScaler().fit_transform(x)\n",
    "\n",
    "y = processed['label']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n",
    "                                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_performance(model, x, y, n=50):\n",
    "    ''' does 50 train test splits and calculates model metrics'''\n",
    "    from sklearn import metrics\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    report = metrics.classification_report(y_test, model.predict(x_test), output_dict=True)\n",
    "    \n",
    "    report_std = {}\n",
    "    \n",
    "    for i in report.keys():\n",
    "        if i == 'accuracy':\n",
    "            report_std[i] = []\n",
    "        else:\n",
    "            report_std[i] = {}\n",
    "            for j in report[i].keys():\n",
    "                report_std[i][j] = []\n",
    "\n",
    "    \n",
    "    scoring = ['balanced_accuracy', 'accuracy', 'f1','precision','recall','roc_auc']\n",
    "\n",
    "    cross_val ={'balanced_accuracy':0, 'accuracy':0, 'f1':0,'precision':0,'recall':0,'roc_auc':0}\n",
    "        \n",
    "    cross_val_std ={'balanced_accuracy':[], 'accuracy':[], 'f1':[],'precision':[],'recall':[],'roc_auc':[]}\n",
    "    \n",
    "    for count in range(n):\n",
    "        \n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n",
    "        \n",
    "        model.fit(x_train, y_train)\n",
    "        \n",
    "        test = metrics.classification_report(y_test, model.predict(x_test), output_dict=True)\n",
    "        \n",
    "        for i in report.keys():\n",
    "            if i == 'accuracy':\n",
    "                report[i] += test[i]\n",
    "                report_std[i].append(test[i])\n",
    "            else:\n",
    "                for j in report[i].keys():\n",
    "                    report[i][j] += test[i][j]\n",
    "                    report_std[i][j].append(test[i][j])\n",
    "       \n",
    "        for p in scoring:\n",
    "            scores = cross_val_score(model, x_train, y_train, scoring = p)\n",
    "\n",
    "            cross_val[p] += np.mean(scores)\n",
    "            \n",
    "            cross_val_std[p].append((np.mean(scores)))\n",
    "            \n",
    "    \n",
    "    for i in scoring:\n",
    "        print(i)\n",
    "        print('mean: %0.3f' % (cross_val[i]/n))\n",
    "        print('std dev: %0.3f' % (np.std(cross_val_std[i])))\n",
    "        print()\n",
    "        \n",
    "    for i in report.keys():\n",
    "        if i == 'accuracy':\n",
    "            report[i] = report[i]/(n+1)\n",
    "            report_std[i] = np.std(report_std[i])\n",
    "        else:\n",
    "            for j in report[i].keys():\n",
    "                report[i][j] = report[i][j]/(n+1)\n",
    "                report_std[i][j] = np.std(report_std[i][j])\n",
    "        \n",
    "    return report, report_std\n",
    "\n",
    "\n",
    "# def model_performance(model, x, y):\n",
    "#     ''' 20 fold cross val score'''\n",
    "#     scoring = ['balanced_accuracy', 'accuracy', 'f1','precision','recall','roc_auc']\n",
    "    \n",
    "#     for p in scoring:\n",
    "#         scores = cross_val_score(model, x, y, cv=20, scoring = p)\n",
    "#         print(p)\n",
    "#         print('mean: %0.3f' % np.mean(scores))\n",
    "#         print('std dev: %0.2f' % np.std(scores))\n",
    "#         print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "c = Counter(pop)\n",
    "\n",
    "test = dict(c)\n",
    "\n",
    "test2 = dict(sorted(test.items(), key=lambda item: -item[1]))\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('dict_diabetes.csv', 'w') as csv_file:  \n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in test2.items():\n",
    "       writer.writerow([key, value])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 20,\n",
       " 'max_features': 'log2',\n",
       " 'min_samples_leaf': 0.001,\n",
       " 'n_estimators': 50}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier()\n",
    "\n",
    "forest_params = {'n_estimators':[i for i in range(110)[10::20]], 'max_depth':[j for j in range(81)[5::15]], \n",
    "                 'min_samples_leaf':list(np.linspace(0.001,0.25,num=10)), 'max_features':['sqrt','log2']}\n",
    "\n",
    "forest_cv = GridSearchCV(forest, forest_params, scoring = 'balanced_accuracy', n_jobs=2).fit(x_train, y_train)\n",
    "\n",
    "forest_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 15, 'min_samples_leaf': 0.015810526315789476, 'n_estimators': 55}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### for diabetes ###\n",
    "\n",
    "# forest = RandomForestClassifier(max_features = 'sqrt')\n",
    "\n",
    "# forest_params = {'n_estimators':[i for i in range(120)[65:85:2]], 'max_depth':[j for j in range(100)[45:65:2]], \n",
    "#                  'min_samples_leaf':list(np.linspace(0.0001,0.002,num=10))}\n",
    "\n",
    "# forest_cv = GridSearchCV(forest, forest_params, scoring = 'balanced_accuracy', n_jobs=2).fit(x_train, y_train)\n",
    "\n",
    "# forest_cv.best_params_\n",
    "\n",
    "### for cirrhosis ###\n",
    "\n",
    "forest = RandomForestClassifier(max_features = 'log2')\n",
    "\n",
    "forest_params = {'n_estimators':[i for i in range(80)[45:65:2]], 'max_depth':[j for j in range(50)[15:35:2]], \n",
    "                 'min_samples_leaf':list(np.linspace(0.0001,0.02,num=20))}\n",
    "\n",
    "forest_cv = GridSearchCV(forest, forest_params, scoring = 'balanced_accuracy', n_jobs=2).fit(x_train, y_train)\n",
    "\n",
    "forest_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### diabetes ###\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 63, min_samples_leaf=0.00157, max_features='sqrt', max_depth = 69)\n",
    "\n",
    "### cirrhosis ###\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# forest = RandomForestClassifier(n_estimators = 55, min_samples_leaf=0.0158, max_features='sqrt', max_depth = 15)\n",
    "\n",
    "# model_performance(forest, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report, report_std = model_performance(forest, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=69, max_features='sqrt',\n",
       "                       min_samples_leaf=0.00157, n_estimators=63)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(x_train, y_train)\n",
    "\n",
    "# print(metrics.classification_report(y_test, forest.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 120}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada = AdaBoostClassifier()\n",
    "\n",
    "ada_params = {'n_estimators':[i for i in range(150)[50:150:10]]}\n",
    "\n",
    "ada_cv = GridSearchCV(ada, ada_params, scoring = 'balanced_accuracy', n_jobs=2).fit(x_train, y_train)\n",
    "\n",
    "ada_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 125}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### diabetes ###\n",
    "\n",
    "# ada = AdaBoostClassifier()\n",
    "\n",
    "# ada_params = {'n_estimators':[i for i in range(150)[75:95]]}\n",
    "\n",
    "# ada_cv = GridSearchCV(ada, ada_params, scoring = 'balanced_accuracy', n_jobs=2).fit(x_train, y_train)\n",
    "\n",
    "# ada_cv.best_params_\n",
    "\n",
    "### cirrhosis ###\n",
    "\n",
    "\n",
    "ada = AdaBoostClassifier()\n",
    "\n",
    "ada_params = {'n_estimators':[i for i in range(150)[115:135]]}\n",
    "\n",
    "ada_cv = GridSearchCV(ada, ada_params, scoring = 'balanced_accuracy', n_jobs=2).fit(x_train, y_train)\n",
    "\n",
    "ada_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### diabetes ###\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada = AdaBoostClassifier(n_estimators = 80)\n",
    "\n",
    "# model_performance(ada, x_train, y_train)\n",
    "\n",
    "\n",
    "### cirrhosis ###\n",
    "\n",
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# ada = AdaBoostClassifier(n_estimators = 125)\n",
    "\n",
    "# model_performance(ada, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report, report_std = model_performance(ada, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(n_estimators=80)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada.fit(x_train, y_train)\n",
    "\n",
    "# print(metrics.classification_report(y_test, ada.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "grad = GradientBoostingClassifier()\n",
    "\n",
    "grad_params = {'n_estimators':[i for i in range(200)[100:300:20]]}\n",
    "\n",
    "grad_cv = GridSearchCV(grad, grad_params).fit(x_train, y_train)\n",
    "\n",
    "grad_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 4, 'n_estimators': 119}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### diabetes ###\n",
    "# grad = GradientBoostingClassifier()\n",
    "\n",
    "# grad_params = {'n_estimators':[i for i in range(200)[115:135:2]], 'max_depth':[i for i in range(6)[3:8]]}\n",
    "\n",
    "# grad_cv = GridSearchCV(grad, grad_params).fit(x_train, y_train)\n",
    "\n",
    "# grad_cv.best_params_\n",
    "\n",
    "\n",
    "grad = GradientBoostingClassifier()\n",
    "\n",
    "grad_params = {'n_estimators':[i for i in range(200)[170:190:2]], 'max_depth':[i for i in range(6)[3:]]}\n",
    "\n",
    "grad_cv = GridSearchCV(grad, grad_params).fit(x_train, y_train)\n",
    "\n",
    "grad_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 114}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### diabetes ###\n",
    "\n",
    "# grad = GradientBoostingClassifier(n_estimators = 119)\n",
    "\n",
    "# grad_params = {'max_depth':[i for i in range(12)[4:10]]}\n",
    "\n",
    "# grad_cv = GridSearchCV(grad, grad_params).fit(x_train, y_train)\n",
    "\n",
    "# grad_cv.best_params_\n",
    "\n",
    "### cirrhosis ###\n",
    "\n",
    "grad = GradientBoostingClassifier(max_depth = 4)\n",
    "\n",
    "grad_params = {'n_estimators':[i for i in range(200)[110:130:2]]}\n",
    "\n",
    "grad_cv = GridSearchCV(grad, grad_params).fit(x_train, y_train)\n",
    "\n",
    "grad_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 'log2', 'min_samples_split': 9}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### diabetes ###\n",
    "\n",
    "# grad = GradientBoostingClassifier(max_depth=4, n_estimators = 119)\n",
    "\n",
    "# grad_params = {'min_samples_split':[i for i in range(15)[2::2]], 'max_features':['sqrt', 'log2']}\n",
    "\n",
    "# grad_cv = GridSearchCV(grad, grad_params).fit(x_train, y_train)\n",
    "\n",
    "# grad_cv.best_params_\n",
    "\n",
    "### cirrhosis ###\n",
    "\n",
    "grad = GradientBoostingClassifier(max_depth=4, n_estimators = 114)\n",
    "\n",
    "grad_params = {'min_samples_split':[i for i in range(10)[2:]], 'max_features':['sqrt', 'log2']}\n",
    "\n",
    "grad_cv = GridSearchCV(grad, grad_params).fit(x_train, y_train)\n",
    "\n",
    "grad_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_split': 10}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### diabetes ###\n",
    "\n",
    "# grad = GradientBoostingClassifier(max_depth=4, n_estimators = 119, max_features='sqrt')\n",
    "\n",
    "# grad_params = {'min_samples_split':[i for i in range(25)[4::2]]}\n",
    "\n",
    "# grad_cv = GridSearchCV(grad, grad_params).fit(x_train, y_train)\n",
    "\n",
    "# grad_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### diabetes ###\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "grad = GradientBoostingClassifier(max_depth=4, n_estimators = 125, max_features='sqrt', min_samples_split=10)\n",
    "\n",
    "# grad.fit(x_train, y_train)\n",
    "\n",
    "# model_performance(grad, x_train, y_train)\n",
    "\n",
    "### cirrhosis ###\n",
    "\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# grad = GradientBoostingClassifier(max_depth=4, n_estimators = 114, max_features='log2', min_samples_split=9)\n",
    "\n",
    "# grad.fit(x_train, y_train)\n",
    "\n",
    "# model_performance(grad, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report, report_std = model_performance(grad, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=4, max_features='sqrt',\n",
       "                           min_samples_split=10, n_estimators=125)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad.fit(x_train, y_train)\n",
    "\n",
    "# print(metrics.classification_report(y_test, grad.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize = (22,12))\n",
    "\n",
    "#plot ROC curve\n",
    "\n",
    "metrics.plot_roc_curve(forest, x_test, y_test, ax = ax[0], name = \"Random Forest\", ls = \"-.\", color='r', linewidth = 2)\n",
    "metrics.plot_roc_curve(ada, x_test, y_test, ax = ax[0], name = \"Adaboost\")\n",
    "metrics.plot_roc_curve(grad, x_test, y_test, ax = ax[0], name = \"Gradient Boosting\", ls = '--', color='black', linewidth=2)\n",
    "ax[0].tick_params(axis='both', labelsize= 14)\n",
    "ax[0].set_xlabel('False Postive Rate', fontsize = 24)\n",
    "ax[0].set_ylabel('True Postive Rate', fontsize = 24)\n",
    "ax[0].text(-0.08, 1.065, \"A\", fontsize=24, fontweight='bold', va='top', ha='right')\n",
    "ax[0].legend(loc = 'lower left', fontsize = 14)\n",
    "\n",
    "#plot precision-recall curve\n",
    "\n",
    "metrics.plot_precision_recall_curve(forest, x_test, y_test, ax = ax[1], name = \"Random Forest\", ls = \"-.\", color='r', linewidth = 2)\n",
    "metrics.plot_precision_recall_curve(ada, x_test, y_test, ax = ax[1], name = \"Adaboost\")\n",
    "metrics.plot_precision_recall_curve(grad, x_test, y_test, ax = ax[1], name = \"Gradient Boosting\", ls = '--', color='black', linewidth=2)\n",
    "ax[1].set_xlabel('Recall', fontsize = 24)\n",
    "ax[1].set_ylabel('Precision', fontsize = 24)\n",
    "ax[1].legend(loc = 'lower left',fontsize=14)\n",
    "ax[1].tick_params(axis='both', labelsize= 16)\n",
    "ax[1].text(-0.08, 1.035, \"B\", fontsize=24, fontweight='bold', va='top', ha='right')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('diabetes_performance',dpi=300)\n",
    "# plt.savefig('cirrhosis_performance',dpi=300)\n",
    "\n",
    "\n",
    "#always put savefig before show(), if not will save empty image.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "\n",
    "grad_importance = permutation_importance(grad, x_test, y_test, scoring = 'balanced_accuracy', n_jobs = 2, n_repeats = 100, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 fold permutation importance\n",
    "\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "impt_score = np.zeros((826,))\n",
    "\n",
    "for i in range(50):\n",
    "    # split data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n",
    "\n",
    "    grad = GradientBoostingClassifier(max_depth=4, n_estimators = 125, max_features='sqrt', min_samples_split=10).fit(x_train, y_train)\n",
    "    \n",
    "    perm_impt = permutation_importance(grad, x_test, y_test, scoring='balanced_accuracy', n_jobs = 2)\n",
    "    \n",
    "    # filter dataset\n",
    "    \n",
    "    impt_score += perm_impt['importances_mean']\n",
    "    \n",
    "temp1 = pd.DataFrame(columns = ['features','impt'])\n",
    "    \n",
    "temp1['features'] = short\n",
    "temp1['impt'] = impt_score/50\n",
    "    \n",
    "temp2 = temp1[temp1['impt'] > 0].copy()\n",
    "temp2.sort_values(by='impt', ascending=False, inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "### diabetes ###\n",
    "\n",
    "# dataframe to record the features and importance\n",
    "\n",
    "# perm_impt = pd.DataFrame(columns = ['features','impt','impt_std'])\n",
    "\n",
    "# perm_impt['features'] = short\n",
    "# perm_impt['impt'] = forest_importance['importances_mean']\n",
    "# perm_impt['impt_std'] = forest_importance['importances_std']\n",
    "\n",
    "# diabetes_impt = perm_impt[perm_impt['impt'] > 0].copy()\n",
    "\n",
    "# diabetes_impt.sort_values(by='impt', ascending=False, inplace=True, ignore_index=True)\n",
    "\n",
    "# # export the csv file\n",
    "# diabetes_impt.to_csv('diabetes_impt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### cirrhosis ###\n",
    "\n",
    "# dataframe to record the features and importance\n",
    "\n",
    "perm_impt = pd.DataFrame(columns = ['features','impt','impt_std'])\n",
    "\n",
    "perm_impt['features'] = short\n",
    "perm_impt['impt'] = grad_importance['importances_mean']\n",
    "perm_impt['impt_std'] = grad_importance['importances_std']\n",
    "\n",
    "cirrho_impt = perm_impt[perm_impt['impt'] > 0].copy()\n",
    "\n",
    "cirrho_impt.sort_values(by='impt', ascending=False, inplace=True, ignore_index=True)\n",
    "\n",
    "# export the csv file\n",
    "cirrho_impt.to_csv('cirrhosis_impt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diabetes_impt = pd.read_csv('diabets_impt.csv')\n",
    "\n",
    "# diabetes_impt.head()\n",
    "\n",
    "cirrho_impt = pd.read_csv('cirrhosis_impt.csv')\n",
    "\n",
    "cirrho_impt.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### diabetes ####\n",
    "\n",
    "#changing labels for control and obese\n",
    "\n",
    "processed['label'].apply(lambda x: 'Diabetes' if x == 1 else 'Ctrl')\n",
    "\n",
    "test = list(temp2['features'][:10])\n",
    "\n",
    "# create a dataframe for mean abundance\n",
    "means = processed.groupby(by = 'label').mean().iloc[:,6:-1]\n",
    "\n",
    "diabetes_means = pd.DataFrame(columns = ['Bacteria','Ctrl','Diabetes'])\n",
    "\n",
    "diabetes_means['Bacteria'] = diabetes_impt['features'][:10]\n",
    "diabetes_means['Diabetes'] = list(means[test].iloc[1, :])\n",
    "diabetes_means['Ctrl'] = list(means[test].iloc[0, :])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### cirrhosis ###\n",
    "\n",
    "# processed['label'].apply(lambda x: 'Cirrhosis' if x == 1 else 'Ctrl')\n",
    "\n",
    "\n",
    "# test = list(cirrho_impt['features'][:10])\n",
    "\n",
    "# # create a dataframe for mean abundance\n",
    "# means = processed.groupby(by = 'label').mean().iloc[:,6:-1]\n",
    "\n",
    "# cirrho_means = pd.DataFrame(columns = ['Bacteria','Ctrl','Cirrhosis'])\n",
    "\n",
    "# cirrho_means['Bacteria'] = cirrho_impt['features'][:10]\n",
    "# cirrho_means['Cirrhosis'] = list(means[test].iloc[1, :])\n",
    "# cirrho_means['Ctrl'] = list(means[test].iloc[0, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### diabetes ###\n",
    "\n",
    "importance vs sample line\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "plt.plot(diabetes_impt['impt'])\n",
    "\n",
    "plt.xlabel('Species', fontsize = 16, fontweight = 'bold', labelpad=10)\n",
    "plt.tick_params(axis='both', labelsize=10)\n",
    "\n",
    "plt.ylabel('Permutation Importance', fontsize = 16, fontweight = 'bold', labelpad=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('diabetes_impt_line.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### cirrhosis ###\n",
    "\n",
    "# importance vs sample line\n",
    "\n",
    "# plt.figure(figsize=(12,8))\n",
    "\n",
    "# plt.plot(cirrho_impt['impt'])\n",
    "\n",
    "# plt.xlabel('Species', fontsize = 16, fontweight = 'bold', labelpad=10)\n",
    "# plt.tick_params(axis='both', labelsize=10)\n",
    "\n",
    "# plt.ylabel('Permutation Importance', fontsize = 16, fontweight = 'bold', labelpad=10)\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "# plt.savefig('cirrhosis_impt_line.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(processed.columns[:7]) + list(temp2['features'][:10]) + ['label']\n",
    "\n",
    "diab = processed[cols].copy()\n",
    "\n",
    "diab['label'] = diab['label'].apply(lambda x: 'Diabetes' if x == 1 else 'Ctrl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "diab_means = diab.groupby(by='label').mean().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = list(temp2['features'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "stuff = list(processed.columns[:7]) + test + ['label']\n",
    "\n",
    "grad_stuff = processed[stuff].copy()\n",
    "\n",
    "grad_stuff['label'] = grad_stuff['label'].apply(lambda x: 'Diabetes' if x == 1 else 'Ctrl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "\n",
    "mann = []\n",
    "\n",
    "for i in test:\n",
    "    ctrl = grad_stuff[i][grad_stuff['label'] == 'Ctrl']\n",
    "    fat = grad_stuff[i][grad_stuff['label'] == 'Diabetes']\n",
    "    mann.append(sp.stats.mannwhitneyu(ctrl, fat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Collinsella aerofaciens',\n",
       " 'Odoribacter splanchnicus',\n",
       " 'Megasphaera unclassified',\n",
       " 'Parabacteroides unclassified',\n",
       " 'Ruminococcus sp 5 1 39BFAA',\n",
       " 'Clostridium bolteae',\n",
       " 'Clostridium citroniae',\n",
       " 'Bifidobacterium adolescentis',\n",
       " 'Bifidobacterium longum',\n",
       " 'Bacteroides vulgatus']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MannwhitneyuResult(statistic=33397.0, pvalue=7.224711382942652e-05),\n",
       " MannwhitneyuResult(statistic=29644.0, pvalue=2.261856987976006e-09),\n",
       " MannwhitneyuResult(statistic=34121.0, pvalue=6.408672929580585e-06),\n",
       " MannwhitneyuResult(statistic=33558.5, pvalue=6.898033308249406e-05),\n",
       " MannwhitneyuResult(statistic=31396.0, pvalue=2.9740521426316235e-07),\n",
       " MannwhitneyuResult(statistic=26114.0, pvalue=2.1677522501221008e-14),\n",
       " MannwhitneyuResult(statistic=28766.0, pvalue=6.125876764052805e-11),\n",
       " MannwhitneyuResult(statistic=38847.0, pvalue=0.14688867697010616),\n",
       " MannwhitneyuResult(statistic=32030.0, pvalue=3.5573550970751967e-06),\n",
       " MannwhitneyuResult(statistic=32459.0, pvalue=1.1807412955071055e-05)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### diabetes ###\n",
    "\n",
    "ind = np.arange(len(diab_means))\n",
    "\n",
    "width = 0.4\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (16,10))\n",
    "\n",
    "color = ['royalblue', 'orange']\n",
    "ax.barh(ind, diab_means['Ctrl'], width, color = color[1], label = 'Ctrl', edgecolor='black')\n",
    "ax.barh(ind + width, diab_means['Diabetes'], width, color = color[0], label = 'Diabetes', edgecolor='black')\n",
    "ax.set(yticks = ind + width/2, yticklabels = temp2['features'][:10])\n",
    "#ax.set_title('Mea', fontsize = 18, fontweight='bold', pad=20)\n",
    "ax.set_xscale('log')\n",
    "ax.set_ylabel('Species', fontsize = 18, fontweight='bold')\n",
    "ax.set_xlabel(\"Relative Abundance\", fontsize = 18, fontweight = 'bold', labelpad = 20)\n",
    "ax.legend(loc='upper right', fontsize = 'x-large')\n",
    "ax.tick_params(axis='both', labelsize = 14)\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "#plt.savefig('diabetes_impt_abundance.png', dpi=200, bbox_inches = \"tight\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### cirrhosis ###\n",
    "\n",
    "# ind = np.arange(len(cirrho_means))\n",
    "\n",
    "# width = 0.4\n",
    "\n",
    "# fig, ax = plt.subplots(figsize = (16,10))\n",
    "\n",
    "# color = ['royalblue', 'orange']\n",
    "# ax.barh(ind, cirrho_means.Cirrhosis, width, color = color[0], label = 'Cirrhosis')\n",
    "# ax.barh(ind + width, cirrho_means.Ctrl, width, color = color[1], label = 'Ctrl')\n",
    "# ax.set(yticks = ind + width/2, yticklabels = cirrho_means.Bacteria)\n",
    "# #ax.set_title('Mea', fontsize = 18, fontweight='bold', pad=20)\n",
    "# ax.set_xscale('log')\n",
    "# ax.set_ylabel('Species', fontsize = 18, fontweight='bold')\n",
    "# ax.set_xlabel(\"Log Relative Abundance\", fontsize = 18, fontweight = 'bold', labelpad = 20)\n",
    "# ax.legend(loc='lower right', fontsize = 'x-large')\n",
    "# ax.tick_params(axis='both', labelsize = 14)\n",
    "# plt.gca().invert_yaxis()\n",
    "\n",
    "# plt.savefig('cirrhosis_impt_abundance.png', dpi=200, bbox_inches = \"tight\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "### for plotting correlation heatmap for all data ###\n",
    "\n",
    "\n",
    "processed = data.copy()\n",
    "\n",
    "# drop columns that are not needed\n",
    "to_drop = list(cols[2:4]) + list(cols[8:20]) + list(cols[21:211])\n",
    "processed.drop(columns = to_drop, inplace = True)\n",
    "\n",
    "# 2nd filtering round\n",
    "\n",
    "bacteria = list(processed.columns)[7:]\n",
    "\n",
    "s = re.compile(r's__\\w+$')\n",
    "\n",
    "not_species = [i for i in bacteria if not s.search(i)]\n",
    "\n",
    "processed.drop(columns = not_species, inplace=True)\n",
    "\n",
    "\n",
    "# create a new column as labels\n",
    "processed['label'] = processed['disease'].apply(lambda x:  0 if (x == 'n') else 1)\n",
    "\n",
    "processed.reset_index(inplace=True, drop=True)\n",
    "\n",
    "species = processed.columns[7:833]\n",
    "\n",
    "processed[species] = processed[species].apply(pd.to_numeric)\n",
    "\n",
    "# rename feature names to shorter one\n",
    "\n",
    "s = re.compile(r's__(\\w+)')\n",
    "\n",
    "short = []\n",
    "\n",
    "for i in list(species):\n",
    "    short.append( s.search(i).group(1).replace(\"_\", \" \"))\n",
    "    \n",
    "new = dict(zip(species, short))\n",
    "\n",
    "processed.rename(columns = new, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = processed.iloc[:, 7:-1].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize = (10,8))\n",
    "\n",
    "sns.heatmap(test, xticklabels = 82, yticklabels = 82, ax=ax, cmap='magma')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('correlation.png', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
